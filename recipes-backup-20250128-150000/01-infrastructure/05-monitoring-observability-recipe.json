{
  "recipe_metadata": {
    "recipe_id": "05-MONITORING-OBSERVABILITY-COMPREHENSIVE",
    "title": "Comprehensive System Monitoring and Observability Stack",
    "version": "1.0.0",
    "created_by": "Claude Sonnet 4",
    "creation_date": "2025-01-28T13:30:00Z",
    "last_updated": "2025-01-28T13:30:00Z",
    "estimated_tokens": 12000,
    "estimated_execution_time": "4-5 hours",
    "difficulty_level": "expert",
    "total_tasks": 1,
    "agent_autonomy_level": "95%",
    "success_rate_target": "99%",
    "compliance_standards": ["SOC 2", "ISO 27001", "GDPR"],
    "architecture_tier": "enterprise-observability"
  },
  "recipe_overview": {
    "description": "Implement a comprehensive monitoring and observability stack for the entire ai-Q system including infrastructure, applications, databases, AI/ML services, and self-hosted services. This recipe delivers Prometheus for metrics collection, Grafana for visualization, Alertmanager for alerting, cAdvisor for container monitoring, Loki for log aggregation, and Jaeger for distributed tracing.",
    "technology_stack": {
      "metrics_collection": "Prometheus, cAdvisor, Node Exporter",
      "visualization": "Grafana",
      "alerting": "Alertmanager",
      "logging": "Loki, Promtail",
      "tracing": "Jaeger",
      "exporters": "PostgreSQL, Redis, Neo4j, Elasticsearch, Weaviate, MinIO"
    },
    "deliverables": [
      "Centralized Prometheus server with comprehensive metrics collection",
      "Grafana instance with pre-built dashboards for all system components",
      "Alertmanager with multi-channel notification routing",
      "Container and system resource monitoring with cAdvisor",
      "Log aggregation and search capabilities with Loki",
      "Distributed tracing for application performance monitoring with Jaeger"
    ]
  },
  "tasks": [
    {
      "id": "05-monitoring-observability-001",
      "title": "Comprehensive System Monitoring and Observability Implementation",
      "description": "Implement a comprehensive monitoring and observability stack for the entire ai-Q system including infrastructure, applications, databases, AI/ML services, and self-hosted services. This recipe delivers Prometheus for metrics collection, Grafana for visualization, Alertmanager for alerting, cAdvisor for container monitoring, Loki for log aggregation, and Jaeger for distributed tracing.",
      "category": "observability",
      "estimated_tokens": 12000,
      "estimated_duration": "4-5 hours",
      "difficulty_level": "expert",
      "prerequisites": {
        "knowledge_required": ["Prometheus Query Language (PromQL)", "Grafana dashboard creation", "Alertmanager configuration", "Docker monitoring", "System metrics"],
        "tools_required": ["Prometheus", "Grafana", "Alertmanager", "cAdvisor", "Node Exporter", "Docker"],
        "environment_setup": ["All ai-Q services running and accessible", "Network connectivity between monitoring components"]
      },
      "inputs": {
        "files_to_read": [
          "docker/compose/unified.yml",
          "config/dynamic/dynamic-config.json",
          "config/network/ip-config.json"
        ],
        "config_dependencies": ["Network configuration", "Service endpoints", "Authentication credentials"],
        "environment_variables": [
          "PROMETHEUS_PORT",
          "GRAFANA_PORT", 
          "ALERTMANAGER_PORT",
          "LOKI_PORT",
          "JAEGER_PORT",
          "SLACK_WEBHOOK_URL",
          "EMAIL_SMTP_SERVER"
        ],
        "external_services": ["Slack", "Email", "PagerDuty"]
      },
      "outputs": {
        "files_created": [
          "docker/compose/monitoring.yml - Monitoring stack services",
          "config/prometheus/prometheus.yml - Prometheus configuration",
          "config/prometheus/rules/system.rules.yml - System alerting rules",
          "config/prometheus/rules/ai-ml.rules.yml - AI/ML service alerting rules",
          "config/alertmanager/config.yml - Alertmanager notification routing",
          "config/grafana/dashboards/system-overview.json - System overview dashboard",
          "config/grafana/dashboards/ai-ml-services.json - AI/ML services dashboard",
          "config/grafana/dashboards/databases.json - Database performance dashboard",
          "config/grafana/dashboards/containers.json - Container resource dashboard",
          "config/grafana/dashboards/network.json - Network traffic dashboard",
          "config/grafana/datasources/prometheus.yml - Prometheus datasource",
          "config/grafana/datasources/loki.yml - Loki datasource",
          "config/loki/loki-config.yml - Loki configuration",
          "config/jaeger/jaeger-config.yml - Jaeger configuration",
          "scripts/monitoring-setup.sh - Automated monitoring setup script",
          "scripts/monitoring-health-check.sh - Monitoring health check script",
          "docs/monitoring/architecture.json - Monitoring architecture documentation"
        ],
        "files_modified": [
          "docker/compose/unified.yml - Add monitoring services",
          "config/dynamic/dynamic-config.json - Add monitoring ports"
        ],
        "api_endpoints": [
          "GET /monitoring/health - Overall monitoring stack health",
          "GET /monitoring/metrics - System metrics summary",
          "GET /monitoring/alerts - Active alerts status",
          "POST /monitoring/alert-test - Test alert delivery"
        ],
        "configuration_updates": ["Monitoring ports", "Alert thresholds", "Dashboard configurations"]
      },
      "dependencies": {
        "required_tasks": ["01-core-infrastructure", "02-unified-docker-system"],
        "optional_tasks": ["03-storage-systems", "04-database-setup"],
        "blocked_tasks": []
      },
      "detailed_instructions": {
        "overview": "This task implements a comprehensive monitoring and observability stack that provides complete visibility into the ai-Q system. The stack includes metrics collection (Prometheus), visualization (Grafana), alerting (Alertmanager), container monitoring (cAdvisor), log aggregation (Loki), and distributed tracing (Jaeger). All components are integrated with pre-built dashboards and alerting rules for proactive system management.",
        "step_by_step_guide": [
          {
            "step": 1,
            "title": "Create Monitoring Stack Docker Compose",
            "description": "Create a comprehensive Docker Compose file for all monitoring services",
            "commands": [
              "# Create monitoring compose file",
              "cat > docker/compose/monitoring.yml << 'EOF'",
              "name: ai-q-monitoring",
              "",
              "services:",
              "  # Prometheus Metrics Collection",
              "  prometheus:",
              "    image: prom/prometheus:v2.48.0",
              "    container_name: ai-q-prometheus",
              "    command:",
              "      - '--config.file=/etc/prometheus/prometheus.yml'",
              "      - '--storage.tsdb.path=/prometheus'",
              "      - '--web.console.libraries=/etc/prometheus/console_libraries'",
              "      - '--web.console.templates=/etc/prometheus/consoles'",
              "      - '--storage.tsdb.retention.time=30d'",
              "      - '--web.enable-lifecycle'",
              "    volumes:",
              "      - ai-q-prometheus-data:/prometheus",
              "      - ../../config/prometheus:/etc/prometheus",
              "    ports:",
              "      - \"${PROMETHEUS_PORT:-9090}:9090\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # Grafana Visualization",
              "  grafana:",
              "    image: grafana/grafana:10.2.0",
              "    container_name: ai-q-grafana",
              "    environment:",
              "      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}",
              "      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource",
              "    volumes:",
              "      - ai-q-grafana-data:/var/lib/grafana",
              "      - ../../config/grafana/provisioning:/etc/grafana/provisioning",
              "    ports:",
              "      - \"${GRAFANA_PORT:-3001}:3000\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/api/health || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # Alertmanager Alerting",
              "  alertmanager:",
              "    image: prom/alertmanager:v0.26.0",
              "    container_name: ai-q-alertmanager",
              "    command:",
              "      - '--config.file=/etc/alertmanager/config.yml'",
              "      - '--storage.path=/alertmanager'",
              "    volumes:",
              "      - ai-q-alertmanager-data:/alertmanager",
              "      - ../../config/alertmanager:/etc/alertmanager",
              "    ports:",
              "      - \"${ALERTMANAGER_PORT:-9093}:9093\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:9093/-/healthy || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # cAdvisor Container Monitoring",
              "  cadvisor:",
              "    image: gcr.io/cadvisor/cadvisor:v0.47.2",
              "    container_name: ai-q-cadvisor",
              "    privileged: true",
              "    ports:",
              "      - \"${CADVISOR_PORT:-8081}:8080\"",
              "    volumes:",
              "      - /:/rootfs:ro",
              "      - /var/run:/var/run:ro",
              "      - /sys:/sys:ro",
              "      - /var/lib/docker/:/var/lib/docker:ro",
              "      - /dev/disk/:/dev/disk:ro",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/healthz\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # Node Exporter System Metrics",
              "  node-exporter:",
              "    image: prom/node-exporter:v1.6.1",
              "    container_name: ai-q-node-exporter",
              "    command:",
              "      - '--path.rootfs=/host'",
              "      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'",
              "    volumes:",
              "      - /:/host:ro,rslave",
              "    ports:",
              "      - \"${NODE_EXPORTER_PORT:-9100}:9100\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:9100/metrics || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # Loki Log Aggregation",
              "  loki:",
              "    image: grafana/loki:2.9.0",
              "    container_name: ai-q-loki",
              "    command: -config.file=/etc/loki/local-config.yaml",
              "    volumes:",
              "      - ai-q-loki-data:/loki",
              "      - ../../config/loki:/etc/loki",
              "    ports:",
              "      - \"${LOKI_PORT:-3100}:3100\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "  # Promtail Log Collection",
              "  promtail:",
              "    image: grafana/promtail:2.9.0",
              "    container_name: ai-q-promtail",
              "    command: -config.file=/etc/promtail/config.yml",
              "    volumes:",
              "      - /var/log:/var/log",
              "      - /var/lib/docker/containers:/var/lib/docker/containers:ro",
              "      - ../../config/promtail:/etc/promtail",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    depends_on:",
              "      - loki",
              "",
              "  # Jaeger Distributed Tracing",
              "  jaeger:",
              "    image: jaegertracing/all-in-one:1.48",
              "    container_name: ai-q-jaeger",
              "    environment:",
              "      - COLLECTOR_OTLP_ENABLED=true",
              "    ports:",
              "      - \"${JAEGER_PORT:-16686}:16686\"",
              "      - \"${JAEGER_COLLECTOR_PORT:-14268}:14268\"",
              "    networks:",
              "      - ai-q-network",
              "    restart: unless-stopped",
              "    healthcheck:",
              "      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:16686/ || exit 1\"]",
              "      interval: 30s",
              "      timeout: 10s",
              "      retries: 3",
              "",
              "volumes:",
              "  ai-q-prometheus-data:",
              "  ai-q-grafana-data:",
              "  ai-q-alertmanager-data:",
              "  ai-q-loki-data:",
              "",
              "networks:",
              "  ai-q-network:",
              "    external: true",
              "EOF"
            ],
            "expected_output": "Monitoring stack Docker Compose file created with all services",
            "troubleshooting": "Verify all image versions are available and network configuration is correct"
          },
          {
            "step": 2,
            "title": "Configure Prometheus Metrics Collection",
            "description": "Configure Prometheus to collect metrics from all system components",
            "commands": [
              "# Create Prometheus configuration",
              "mkdir -p config/prometheus/rules",
              "cat > config/prometheus/prometheus.yml << 'EOF'",
              "global:",
              "  scrape_interval: 15s",
              "  evaluation_interval: 15s",
              "",
              "rule_files:",
              "  - 'rules/*.yml'",
              "",
              "alerting:",
              "  alertmanagers:",
              "    - static_configs:",
              "        - targets: ['alertmanager:9093']",
              "",
              "scrape_configs:",
              "  # Prometheus itself",
              "  - job_name: 'prometheus'",
              "    static_configs:",
              "      - targets: ['localhost:9090']",
              "",
              "  # Node Exporter",
              "  - job_name: 'node-exporter'",
              "    static_configs:",
              "      - targets: ['node-exporter:9100']",
              "",
              "  # cAdvisor",
              "  - job_name: 'cadvisor'",
              "    static_configs:",
              "      - targets: ['cadvisor:8080']",
              "",
              "  # PostgreSQL",
              "  - job_name: 'postgres-exporter'",
              "    static_configs:",
              "      - targets: ['postgres-exporter:9187']",
              "",
              "  # Redis",
              "  - job_name: 'redis-exporter'",
              "    static_configs:",
              "      - targets: ['redis-exporter:9121']",
              "",
              "  # Elasticsearch",
              "  - job_name: 'elasticsearch-exporter'",
              "    static_configs:",
              "      - targets: ['elasticsearch-exporter:9114']",
              "",
              "  # Neo4j",
              "  - job_name: 'neo4j-exporter'",
              "    static_configs:",
              "      - targets: ['neo4j-exporter:9121']",
              "",
              "  # Weaviate",
              "  - job_name: 'weaviate-exporter'",
              "    static_configs:",
              "      - targets: ['weaviate-exporter:8080']",
              "",
              "  # MinIO",
              "  - job_name: 'minio-exporter'",
              "    static_configs:",
              "      - targets: ['minio-exporter:9290']",
              "",
              "  # AI/ML Services",
              "  - job_name: 'ollama'",
              "    static_configs:",
              "      - targets: ['ollama:11434']",
              "    metrics_path: '/api/tags'",
              "",
              "  - job_name: 'openwebui'",
              "    static_configs:",
              "      - targets: ['openwebui:8080']",
              "    metrics_path: '/api/v1/models'",
              "",
              "  # Self-hosted Services",
              "  - job_name: 'gitea'",
              "    static_configs:",
              "      - targets: ['gitea:3000']",
              "",
              "  - job_name: 'nextcloud'",
              "    static_configs:",
              "      - targets: ['nextcloud:80']",
              "",
              "  - job_name: 'admin-panel'",
              "    static_configs:",
              "      - targets: ['admin-panel:80']",
              "",
              "  # Main Application",
              "  - job_name: 'ai-q-app'",
              "    static_configs:",
              "      - targets: ['ai-q-app:8000']",
              "    metrics_path: '/metrics'",
              "EOF"
            ],
            "expected_output": "Prometheus configuration created with all system components as scrape targets",
            "troubleshooting": "Verify all service endpoints are accessible and metrics endpoints are available"
          },
          {
            "step": 3,
            "title": "Create Alerting Rules",
            "description": "Define comprehensive alerting rules for all system components",
            "commands": [
              "# Create system alerting rules",
              "cat > config/prometheus/rules/system.rules.yml << 'EOF'",
              "groups:",
              "  - name: system_alerts",
              "    rules:",
              "      # System resource alerts",
              "      - alert: HighCPUUsage",
              "        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) > 80",
              "        for: 5m",
              "        labels:",
              "          severity: warning",
              "        annotations:",
              "          summary: \"High CPU usage on {{ $labels.instance }}\"",
              "          description: \"CPU usage is above 80% for more than 5 minutes\"",
              "",
              "      - alert: HighMemoryUsage",
              "        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85",
              "        for: 5m",
              "        labels:",
              "          severity: warning",
              "        annotations:",
              "          summary: \"High memory usage on {{ $labels.instance }}\"",
              "          description: \"Memory usage is above 85% for more than 5 minutes\"",
              "",
              "      - alert: HighDiskUsage",
              "        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 90",
              "        for: 5m",
              "        labels:",
              "          severity: critical",
              "        annotations:",
              "          summary: \"High disk usage on {{ $labels.instance }}\"",
              "          description: \"Disk usage is above 90% for more than 5 minutes\"",
              "",
              "      # Container alerts",
              "      - alert: ContainerDown",
              "        expr: absent(container_last_seen)",
              "        for: 1m",
              "        labels:",
              "          severity: critical",
              "        annotations:",
              "          summary: \"Container {{ $labels.name }} is down\"",
              "          description: \"Container has not been seen for more than 1 minute\"",
              "",
              "      - alert: ContainerHighMemoryUsage",
              "        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes * 100) > 85",
              "        for: 5m",
              "        labels:",
              "          severity: warning",
              "        annotations:",
              "          summary: \"High memory usage in container {{ $labels.name }}\"",
              "          description: \"Container memory usage is above 85% for more than 5 minutes\"",
              "",
              "      - alert: ContainerHighCPUUsage",
              "        expr: (rate(container_cpu_usage_seconds_total[5m]) / container_spec_cpu_quota * 100) > 80",
              "        for: 5m",
              "        labels:",
              "          severity: warning",
              "        annotations:",
              "          summary: \"High CPU usage in container {{ $labels.name }}\"",
              "          description: \"Container CPU usage is above 80% for more than 5 minutes\"",
              "EOF",
              "",
              "# Create AI/ML service alerting rules",
              "cat > config/prometheus/rules/ai-ml.rules.yml << 'EOF'",
              "groups:",
              "  - name: ai_ml_alerts",
              "    rules:",
              "      # Ollama alerts",
              "      - alert: OllamaDown",
              "        expr: up{job=\"ollama\"} == 0",
              "        for: 1m",
              "        labels:",
              "          severity: critical",
              "        annotations:",
              "          summary: \"Ollama service is down\"",
              "          description: \"Ollama LLM service is not responding\"",
              "",
              "      # OpenWebUI alerts",
              "      - alert: OpenWebUIDown",
              "        expr: up{job=\"openwebui\"} == 0",
              "        for: 1m",
              "        labels:",
              "          severity: critical",
              "        annotations:",
              "          summary: \"OpenWebUI service is down\"",
              "          description: \"OpenWebUI interface is not responding\"",
              "",
              "      # Model loading alerts",
              "      - alert: ModelLoadFailure",
              "        expr: ollama_model_load_duration_seconds > 300",
              "        for: 1m",
              "        labels:",
              "          severity: warning",
              "        annotations:",
              "          summary: \"Model loading is taking too long\"",
              "          description: \"Model loading duration exceeds 5 minutes\"",
              "EOF"
            ],
            "expected_output": "Comprehensive alerting rules created for system and AI/ML services",
            "troubleshooting": "Verify rule syntax and ensure all metrics referenced exist"
          },
          {
            "step": 4,
            "title": "Configure Alertmanager Notifications",
            "description": "Set up Alertmanager to route alerts to appropriate notification channels",
            "commands": [
              "# Create Alertmanager configuration",
              "mkdir -p config/alertmanager",
              "cat > config/alertmanager/config.yml << 'EOF'",
              "global:",
              "  resolve_timeout: 5m",
              "  slack_api_url: '${SLACK_WEBHOOK_URL}'",
              "",
              "route:",
              "  group_by: ['alertname', 'severity']",
              "  group_wait: 10s",
              "  group_interval: 10s",
              "  repeat_interval: 1h",
              "  receiver: 'slack-notifications'",
              "  routes:",
              "    - match:",
              "        severity: critical",
              "      receiver: 'critical-alerts'",
              "      repeat_interval: 30m",
              "",
              "receivers:",
              "  - name: 'slack-notifications'",
              "    slack_configs:",
              "      - channel: '#ai-q-alerts'",
              "        title: '{{ template \"slack.title\" . }}'",
              "        text: '{{ template \"slack.text\" . }}'",
              "        send_resolved: true",
              "",
              "  - name: 'critical-alerts'",
              "    slack_configs:",
              "      - channel: '#ai-q-critical'",
              "        title: '🚨 CRITICAL: {{ template \"slack.title\" . }}'",
              "        text: '{{ template \"slack.text\" . }}'",
              "        send_resolved: true",
              "    email_configs:",
              "      - to: 'admin@ai-q.local'",
              "        from: 'alerts@ai-q.local'",
              "        smarthost: '${EMAIL_SMTP_SERVER}'",
              "        subject: 'CRITICAL ALERT: {{ template \"email.subject\" . }}'",
              "",
              "templates:",
              "  - '/etc/alertmanager/template/*.tmpl'",
              "EOF"
            ],
            "expected_output": "Alertmanager configured with Slack and email notification channels",
            "troubleshooting": "Verify Slack webhook URL and email SMTP server configuration"
          },
          {
            "step": 5,
            "title": "Create Grafana Dashboards",
            "description": "Create comprehensive Grafana dashboards for all system components",
            "commands": [
              "# Create Grafana datasource configurations",
              "mkdir -p config/grafana/provisioning/datasources",
              "cat > config/grafana/provisioning/datasources/prometheus.yml << 'EOF'",
              "apiVersion: 1",
              "",
              "datasources:",
              "  - name: Prometheus",
              "    type: prometheus",
              "    access: proxy",
              "    url: http://prometheus:9090",
              "    isDefault: true",
              "    editable: true",
              "",
              "  - name: Loki",
              "    type: loki",
              "    access: proxy",
              "    url: http://loki:3100",
              "    editable: true",
              "EOF",
              "",
              "# Create system overview dashboard",
              "mkdir -p config/grafana/provisioning/dashboards",
              "cat > config/grafana/provisioning/dashboards/system-overview.json << 'EOF'",
              "{",
              "  \"dashboard\": {",
              "    \"title\": \"AI-Q System Overview\",",
              "    \"panels\": [",
              "      {",
              "        \"title\": \"CPU Usage\",",
              "        \"type\": \"stat\",",
              "        \"targets\": [",
              "          {",
              "            \"expr\": \"100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)\",",
              "            \"legendFormat\": \"CPU %\"",
              "          }",
              "        ]",
              "      },",
              "      {",
              "        \"title\": \"Memory Usage\",",
              "        \"type\": \"stat\",",
              "        \"targets\": [",
              "          {",
              "            \"expr\": \"(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100\",",
              "            \"legendFormat\": \"Memory %\"",
              "          }",
              "        ]",
              "      },",
              "      {",
              "        \"title\": \"Disk Usage\",",
              "        \"type\": \"stat\",",
              "        \"targets\": [",
              "          {",
              "            \"expr\": \"(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100\",",
              "            \"legendFormat\": \"Disk %\"",
              "          }",
              "        ]",
              "      }",
              "    ]",
              "  }",
              "}",
              "EOF"
            ],
            "expected_output": "Grafana dashboards and datasources configured",
            "troubleshooting": "Verify dashboard JSON syntax and datasource connectivity"
          },
          {
            "step": 6,
            "title": "Deploy Monitoring Stack",
            "description": "Deploy the complete monitoring stack and verify all components",
            "commands": [
              "# Deploy monitoring stack",
              "cd docker/compose",
              "docker-compose -f monitoring.yml up -d",
              "",
              "# Wait for services to start",
              "sleep 30",
              "",
              "# Verify all services are running",
              "docker-compose -f monitoring.yml ps",
              "",
              "# Test Prometheus targets",
              "curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .labels.job, health: .health}'",
              "",
              "# Test Grafana connectivity",
              "curl -s http://localhost:3001/api/health",
              "",
              "# Test Alertmanager",
              "curl -s http://localhost:9093/api/v1/status",
              "",
              "# Create monitoring health check script",
              "cat > ../../scripts/monitoring-health-check.sh << 'EOF'",
              "#!/bin/bash",
              "echo \"Checking monitoring stack health...\"",
              "echo \"Prometheus: $(curl -s http://localhost:9090/-/healthy || echo 'DOWN')\"",
              "echo \"Grafana: $(curl -s http://localhost:3001/api/health | jq -r '.database' || echo 'DOWN')\"",
              "echo \"Alertmanager: $(curl -s http://localhost:9093/-/healthy || echo 'DOWN')\"",
              "echo \"cAdvisor: $(curl -s http://localhost:8081/healthz || echo 'DOWN')\"",
              "echo \"Loki: $(curl -s http://localhost:3100/ready || echo 'DOWN')\"",
              "EOF",
              "chmod +x ../../scripts/monitoring-health-check.sh"
            ],
            "expected_output": "Monitoring stack deployed and all services verified as healthy",
            "troubleshooting": "Check container logs for any startup issues and verify network connectivity"
          }
        ]
      },
      "acceptance_criteria": {
        "functional_requirements": [
          "All monitoring services (Prometheus, Grafana, Alertmanager, cAdvisor, Loki, Jaeger) are running and healthy",
          "Prometheus is collecting metrics from all system components including databases, AI/ML services, and infrastructure",
          "Grafana dashboards are displaying system metrics, container resources, and service health",
          "Alertmanager is configured with notification channels and can send test alerts",
          "Log aggregation is working with Loki and Promtail collecting container and system logs",
          "Distributed tracing is available through Jaeger for application performance monitoring"
        ],
        "performance_requirements": [
          "Prometheus metrics collection completes within 15 seconds",
          "Grafana dashboard queries respond within 3 seconds",
          "Alert notifications are delivered within 30 seconds",
          "Log search queries in Grafana complete within 5 seconds",
          "System resource overhead from monitoring is less than 10%"
        ],
        "security_requirements": [
          "All monitoring endpoints are secured with authentication",
          "Sensitive metrics and logs are properly filtered",
          "Alert notifications are encrypted in transit",
          "Access to monitoring dashboards is role-based",
          "Audit logging is enabled for all monitoring operations"
        ],
        "integration_requirements": [
          "Monitoring stack integrates with existing ai-Q services",
          "Custom metrics are exposed by all application components",
          "Health checks are implemented for all monitored services",
          "Monitoring data is persisted across container restarts",
          "Backup and restore procedures are available for monitoring data"
        ]
      }
    }
  ]
} 