# TOKEN COUNT GUIDELINES - AI-Q KNOWLEDGE LIBRARY SYSTEM
# TOKEN COUNT: ~1,847 tokens
---
version: "1.0"
last_updated: "2025-01-27T12:00:00Z"
created_by: "Claude Sonnet 4 - Claude Sonnet 4"
purpose: >
  Comprehensive guidelines for adding token count metadata to different file types
  without breaking syntax or causing parsing errors.

# OVERVIEW
overview:
  purpose: "Track token usage across all project files for context window management"
  importance: "Critical for managing AI model context limits and optimizing performance"
  scope: "All project files including code, configuration, and documentation"

# FILE TYPE SPECIFIC GUIDELINES

## JSON FILES
json_files:
  approach: "Add _metadata field within JSON structure"
  structure: |
    {
      "_metadata": {
        "token_count": 1234,
        "token_count_estimated": true,
        "last_updated": "2025-01-27T12:00:00Z",
        "created_by": "Claude Sonnet 4",
        "model_version": "Claude Sonnet 4"
      },
      "actual_data": {
        // ... rest of JSON content
      }
    }
  
  advantages:
    - "Maintains valid JSON syntax"
    - "Can be parsed by any JSON parser"
    - "Metadata is part of the data structure"
    - "Can include additional metadata fields"
  
  disadvantages:
    - "Adds extra fields to JSON structure"
    - "May affect existing code that expects specific structure"
  
  implementation:
    - "Use _metadata field at root level"
    - "Include token_count as integer"
    - "Include token_count_estimated as boolean"
    - "Include last_updated timestamp"
    - "Include agent identification"

## YAML FILES
yaml_files:
  approach: "Add comment-style metadata at top of file"
  structure: |
    # TOKEN COUNT: ~1,234 tokens
    # Created by: Claude Sonnet 4
    # Model Version: Claude Sonnet 4
    # Timestamp: 2025-01-27T12:00:00Z
    ---
    version: "1.0"
    # ... rest of YAML content
  
  advantages:
    - "Standard YAML comment format"
    - "Doesn't affect YAML structure"
    - "Easy to read and parse"
    - "Can include multiple metadata lines"
  
  disadvantages:
    - "Comments may be stripped by some parsers"
    - "Not part of the actual data structure"
  
  implementation:
    - "Place after title line if exists"
    - "Use consistent format: # TOKEN COUNT: ~X tokens"
    - "Include agent identification"
    - "Include timestamp"

## MARKDOWN FILES
markdown_files:
  approach: "Add comment-style metadata at top of file"
  structure: |
    <!-- TOKEN COUNT: ~1,234 tokens -->
    <!-- Created by: Claude Sonnet 4 -->
    <!-- Model Version: Claude Sonnet 4 -->
    <!-- Timestamp: 2025-01-27T12:00:00Z -->
    
    # Document Title
    
    Document content...
  
  advantages:
    - "HTML comments are standard in Markdown"
    - "Don't affect Markdown rendering"
    - "Can be parsed by HTML parsers"
    - "Hidden from rendered output"
  
  disadvantages:
    - "HTML comments may be stripped by some processors"
    - "Not visible in plain text view"
  
  implementation:
    - "Use HTML comment format: <!-- TOKEN COUNT: ~X tokens -->"
    - "Place at very top of file"
    - "Include agent identification"
    - "Include timestamp"

## TYPESCRIPT/JAVASCRIPT FILES
typescript_javascript_files:
  approach: "Add comment-style metadata at top of file"
  structure: |
    /**
     * TOKEN COUNT: ~1,234 tokens
     * Created by: Claude Sonnet 4
     * Model Version: Claude Sonnet 4
     * Timestamp: 2025-01-27T12:00:00Z
     */
    
    // ... rest of code
  
  advantages:
    - "Standard JSDoc comment format"
    - "Can be parsed by documentation generators"
    - "Doesn't affect code execution"
    - "Can include additional documentation"
  
  disadvantages:
    - "Comments may be stripped by minifiers"
    - "Not part of the actual code structure"
  
  implementation:
    - "Use JSDoc comment format: /** ... */"
    - "Place at top of file"
    - "Include agent identification"
    - "Include timestamp"

## PYTHON FILES
python_files:
  approach: "Add comment-style metadata at top of file"
  structure: |
    # TOKEN COUNT: ~1,234 tokens
    # Created by: Claude Sonnet 4
    # Model Version: Claude Sonnet 4
    # Timestamp: 2025-01-27T12:00:00Z
    """
    Module docstring...
    """
    
    # ... rest of code
  
  advantages:
    - "Standard Python comment format"
    - "Doesn't affect code execution"
    - "Easy to read and parse"
    - "Can include multiple metadata lines"
  
  disadvantages:
    - "Comments may be stripped by some processors"
    - "Not part of the actual code structure"
  
  implementation:
    - "Use # comment format"
    - "Place at top of file"
    - "Include agent identification"
    - "Include timestamp"

## TEXT FILES
text_files:
  approach: "Add comment-style metadata at top of file"
  structure: |
    # TOKEN COUNT: ~1,234 tokens
    # Created by: Claude Sonnet 4
    # Model Version: Claude Sonnet 4
    # Timestamp: 2025-01-27T12:00:00Z
    
    Text content...
  
  advantages:
    - "Simple and readable"
    - "Doesn't affect content"
    - "Easy to parse"
    - "Can include multiple metadata lines"
  
  disadvantages:
    - "Comments may be stripped by some processors"
    - "Not part of the actual content structure"
  
  implementation:
    - "Use # comment format"
    - "Place at top of file"
    - "Include agent identification"
    - "Include timestamp"

# TOKEN COUNTING METHODOLOGY
token_counting:
  estimation_method: "Word-based approximation"
  formula: "max(words, characters / 4)"
  accuracy: "Approximate - within 10-20% of actual token count"
  purpose: "Context window management and optimization"
  
  considerations:
    - "Different AI models may tokenize differently"
    - "Code files may have different tokenization than text"
    - "Special characters and formatting affect token count"
    - "Regular re-counting may be necessary"

# AUTOMATION
automation:
  script: "scripts/token_counter.py"
  features:
    - "Automatic file type detection"
    - "Appropriate metadata format for each file type"
    - "Batch processing of multiple files"
    - "Dry-run mode for testing"
    - "Summary reporting"
  
  usage:
    - "python scripts/token_counter.py --path . --dry-run"
    - "python scripts/token_counter.py --path . --summary"
    - "python scripts/token_counter.py --extensions .json .yml"

# BEST PRACTICES
best_practices:
  consistency:
    - "Use consistent format across all files"
    - "Include agent identification in all metadata"
    - "Include timestamp in all metadata"
    - "Use same token counting methodology"
  
  maintenance:
    - "Update token counts when files change significantly"
    - "Regular validation of token count accuracy"
    - "Document any changes to counting methodology"
    - "Keep automation scripts updated"
  
  validation:
    - "Verify JSON files remain valid after metadata addition"
    - "Test YAML files parse correctly"
    - "Ensure Markdown renders properly"
    - "Validate code files compile/execute correctly"

# CONCLUSION
conclusion: >
  Token count metadata is essential for managing AI model context windows and
  optimizing performance. Each file type requires a different approach to maintain
  syntax validity while providing the necessary metadata. The automated script
  handles this complexity and ensures consistent implementation across all file types. 