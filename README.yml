# AI-Q Knowledge Library System
# TOKEN COUNT: ~3,258 tokens
---
version: "1.0"
last_updated: "2025-07-03T00:00:00Z"
created_by: "Claude Sonnet 4"
purpose: >
  Comprehensive documentation for the AI-Q Knowledge Library System, a dual-representation
  knowledge management framework designed for enterprise distribution and zero technical debt.

# PROJECT OVERVIEW
project_overview:
  name: "AI-Q Knowledge Library System (KLS)"
  description: >
    A comprehensive dual-representation knowledge management framework that stores knowledge
    in both structured (YAML) and unstructured (RAG) formats, providing unified access
    through a gRPC service interface.
  
  key_features:
    - "Dual-representation knowledge storage (structured + RAG)"
    - "Enterprise-grade security and compliance"
    - "Cross-platform compatibility"
    - "Zero technical debt architecture"
    - "Production-only testing methodology"
    - "Feature flag system for safe deployments"
    - "Comprehensive monitoring and observability"
    - "Scalable microservices architecture"
  
  target_audience:
    - "Enterprise organizations"
    - "Knowledge management teams"
    - "AI/ML development teams"
    - "Research institutions"
    - "Educational organizations"

# ARCHITECTURE OVERVIEW
architecture:
  core_components:
    api_server: "FastAPI-based REST and gRPC services"
    web_dashboard: "React/Next.js frontend interface"
    content_processor: "Document processing and analysis pipeline"
    rag_engine: "Retrieval-Augmented Generation system"
    knowledge_graph: "Neo4j-based relationship management"
    vector_database: "Weaviate for semantic search"
    object_storage: "MinIO for artifact storage"
    search_engine: "Elasticsearch for keyword search"
  
  data_flow:
    1. "Content ingestion through multiple sources"
    2. "Processing and metadata extraction"
    3. "Vector embedding generation"
    4. "Knowledge graph relationship mapping"
    5. "Indexing in search and vector databases"
    6. "Unified retrieval through API services"
  
  technology_stack:
    backend:
      - "Python 3.8+ with FastAPI"
      - "gRPC for high-performance communication"
      - "PostgreSQL for structured data"
      - "Redis for caching"
      - "Elasticsearch for search"
      - "Neo4j for knowledge graph"
      - "Weaviate for vector storage"
      - "MinIO for object storage"
    
    frontend:
      - "React 18 with TypeScript"
      - "Next.js 14 for SSR/SSG"
      - "Tailwind CSS for styling"
      - "Framer Motion for animations"
      - "Monaco Editor for code editing"
    
    infrastructure:
      - "Docker and Docker Compose"
      - "Nginx reverse proxy"
      - "Prometheus for monitoring"
      - "Grafana for visualization"
      - "Automated backup systems"

# QUICK START
quick_start:
  prerequisites:
    - "Docker and Docker Compose"
    - "Python 3.8+"
    - "Node.js 18+"
    - "Git"
    - "Windows Command Prompt (not PowerShell)"
  
  installation_steps:
    1. "Clone the repository"
       command: "git clone https://github.com/kos-org/ai-q-kls.git"
       directory: "cd ai-q-kls"
    
    2. "Set up Python virtual environment"
       command: "python -m venv venv"
       activation: "venv\\Scripts\\activate.bat"
    
    3. "Install Python dependencies"
       command: "pip install -r requirements.txt"
    
    4. "Install Node.js dependencies"
       command: "npm install"
    
    5. "Configure environment variables"
       file: ".env"
       template: "Copy .env.example to .env and update values"
    
    6. "Start all services"
       command: "docker-compose up -d"
    
    7. "Initialize the system"
       command: "python scripts/init_system.py"
    
    8. "Access the application"
       web_dashboard: "http://localhost:3000"
       api_documentation: "http://localhost:8000/docs"
       grafana_dashboard: "http://localhost:3001"

# CONFIGURATION
configuration:
  environment_variables:
    database:
      DATABASE_URL: "PostgreSQL connection string"
      POSTGRES_PASSWORD: "PostgreSQL password"
    
    cache:
      REDIS_URL: "Redis connection string"
      REDIS_PASSWORD: "Redis password"
    
    search:
      ELASTICSEARCH_URL: "Elasticsearch endpoint"
      ELASTIC_PASSWORD: "Elasticsearch password"
    
    graph:
      NEO4J_URI: "Neo4j connection string"
      NEO4J_USER: "Neo4j username"
      NEO4J_PASSWORD: "Neo4j password"
    
    vector:
      WEAVIATE_URL: "Weaviate endpoint"
    
    storage:
      MINIO_ENDPOINT: "MinIO endpoint"
      MINIO_ACCESS_KEY: "MinIO access key"
      MINIO_SECRET_KEY: "MinIO secret key"
    
    security:
      JWT_SECRET: "JWT signing secret"
      ENCRYPTION_KEY: "Data encryption key"
    
    monitoring:
      GRAFANA_PASSWORD: "Grafana admin password"
  
  feature_flags:
    system:
      rag_engine: true
      knowledge_graph: true
      ai_agents: false
      mobile_access: false
      home_automation: false
    
    security:
      encryption_at_rest: true
      encryption_in_transit: true
      audit_logging: true
      access_control: true
    
    performance:
      caching: true
      compression: true
      load_balancing: true
      auto_scaling: false

# USAGE GUIDES
usage_guides:
  content_management:
    adding_content:
      - "Upload files through web interface"
      - "Use API endpoints for bulk upload"
      - "Configure automatic directory monitoring"
      - "Set up web scraping for external content"
    
    content_processing:
      - "Automatic format detection and conversion"
      - "Metadata extraction and enrichment"
      - "Vector embedding generation"
      - "Knowledge graph relationship mapping"
    
    content_retrieval:
      - "Semantic search through RAG engine"
      - "Keyword search via Elasticsearch"
      - "Graph-based relationship queries"
      - "Hybrid search combining multiple methods"
  
  api_usage:
    authentication:
      - "JWT-based authentication"
      - "API key authentication"
      - "OAuth2 integration (optional)"
    
    endpoints:
      content: "/api/v1/content"
      search: "/api/v1/search"
      graph: "/api/v1/graph"
      rag: "/api/v1/rag"
      health: "/api/v1/health"
    
    examples:
      search_query: |
        curl -X POST "http://localhost:8000/api/v1/search" \
          -H "Authorization: Bearer YOUR_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{"query": "machine learning", "limit": 10}'
      
      rag_query: |
        curl -X POST "http://localhost:8000/api/v1/rag" \
          -H "Authorization: Bearer YOUR_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{"question": "What is the best approach for NLP?", "context_limit": 5}'

# DEVELOPMENT
development:
  setup:
    development_environment:
      - "Clone repository and set up virtual environment"
      - "Install development dependencies"
      - "Configure development environment variables"
      - "Start development services"
    
    coding_standards:
      - "Follow PEP 8 for Python code"
      - "Use TypeScript for all JavaScript/TypeScript code"
      - "Implement comprehensive error handling"
      - "Write unit tests for all functions"
      - "Use production data for all testing"
    
    testing:
      - "Unit tests with pytest"
      - "Integration tests with testcontainers"
      - "End-to-end tests with Playwright"
      - "Performance tests with locust"
      - "Security tests with bandit and safety"
  
  deployment:
    production_deployment:
      - "Use Docker Compose for containerized deployment"
      - "Configure reverse proxy with Nginx"
      - "Set up SSL certificates"
      - "Configure monitoring and alerting"
      - "Implement automated backups"
    
    scaling:
      - "Horizontal scaling with load balancers"
      - "Database read replicas"
      - "Redis clustering"
      - "Elasticsearch clustering"
      - "Auto-scaling based on metrics"

# MONITORING AND OBSERVABILITY
monitoring:
  metrics:
    system_metrics:
      - "CPU and memory usage"
      - "Disk I/O and storage"
      - "Network traffic"
      - "Database performance"
    
    application_metrics:
      - "API response times"
      - "Request rates and errors"
      - "Search query performance"
      - "RAG response quality"
    
    business_metrics:
      - "Content processing rates"
      - "User engagement metrics"
      - "Search effectiveness"
      - "Knowledge graph growth"
  
  alerting:
    critical_alerts:
      - "Service unavailability"
      - "High error rates"
      - "Performance degradation"
      - "Security incidents"
    
    warning_alerts:
      - "Resource usage approaching limits"
      - "Backup failures"
      - "Certificate expiration"
      - "Disk space warnings"

# SECURITY
security:
  authentication:
    - "Multi-factor authentication for admin access"
    - "Role-based access control"
    - "Session management with timeouts"
    - "API rate limiting"
  
  data_protection:
    - "Encryption at rest for all data"
    - "Encryption in transit (TLS 1.3)"
    - "Data classification and masking"
    - "Audit logging for all access"
  
  compliance:
    - "GDPR compliance for data privacy"
    - "SOC 2 Type II certification"
    - "ISO 27001 information security"
    - "Regular security assessments"

# TROUBLESHOOTING
troubleshooting:
  common_issues:
    service_startup:
      - "Check Docker service status"
      - "Verify port availability"
      - "Check environment variable configuration"
      - "Review service logs"
    
    database_connection:
      - "Verify database credentials"
      - "Check network connectivity"
      - "Ensure database is running"
      - "Review connection pool settings"
    
    performance_issues:
      - "Monitor resource usage"
      - "Check query performance"
      - "Review caching configuration"
      - "Analyze slow query logs"
  
  logs:
    log_locations:
      - "Application logs: ./logs/app.log"
      - "Nginx logs: ./logs/nginx/"
      - "Docker logs: docker-compose logs"
      - "System logs: journalctl"
    
    log_levels:
      - "DEBUG: Detailed debugging information"
      - "INFO: General information messages"
      - "WARNING: Warning messages"
      - "ERROR: Error messages"
      - "CRITICAL: Critical error messages"

# CONTRIBUTING
contributing:
  development_workflow:
    1. "Fork the repository"
    2. "Create a feature branch"
    3. "Make your changes"
    4. "Write tests for new functionality"
    5. "Ensure all tests pass"
    6. "Submit a pull request"
    7. "Code review and approval"
    8. "Merge to main branch"
  
  code_standards:
    - "Follow established coding conventions"
    - "Write comprehensive documentation"
    - "Include type hints for Python code"
    - "Use TypeScript for all frontend code"
    - "Implement proper error handling"
    - "Write unit and integration tests"
  
  testing_requirements:
    - "All new code must have tests"
    - "Tests must use production data"
    - "Maintain minimum 90% code coverage"
    - "Performance tests for new features"
    - "Security tests for all endpoints"

# LICENSE AND SUPPORT
license:
  type: "MIT License"
  copyright: "Â© 2025 kOS Development Team"
  permissions:
    - "Commercial use"
    - "Modification"
    - "Distribution"
    - "Private use"
  limitations:
    - "Liability"
    - "Warranty"

support:
  documentation:
    - "API Documentation: http://localhost:8000/docs"
    - "User Guide: ./docs/user-guide.md"
    - "Developer Guide: ./docs/developer-guide.md"
    - "Architecture Guide: ./docs/architecture.md"
  
  community:
    - "GitHub Issues: https://github.com/kos-org/ai-q-kls/issues"
    - "Discussions: https://github.com/kos-org/ai-q-kls/discussions"
    - "Wiki: https://github.com/kos-org/ai-q-kls/wiki"
  
  contact:
    - "Email: support@kos-org.com"
    - "Security: security@kos-org.com"
    - "Enterprise: enterprise@kos-org.com"

# CHANGELOG
changelog:
  version_1_0_0:
    date: "2025-07-03"
    changes:
      - "Initial release of AI-Q Knowledge Library System"
      - "Dual-representation knowledge storage"
      - "Enterprise-grade security and compliance"
      - "Comprehensive monitoring and observability"
      - "Cross-platform compatibility"
      - "Zero technical debt architecture"
      - "Production-only testing methodology"
      - "Feature flag system"
      - "Docker-based deployment"
      - "Complete API documentation"

# ROADMAP
roadmap:
  upcoming_features:
    - "Advanced AI-powered content analysis"
    - "Mobile application support"
    - "Real-time collaboration features"
    - "Advanced knowledge graph visualization"
    - "Machine learning model integration"
    - "Multi-language support"
    - "Advanced security features"
    - "Performance optimizations"
  
  long_term_goals:
    - "Federated knowledge sharing"
    - "Advanced AI agents integration"
    - "Blockchain-based knowledge verification"
    - "Quantum computing optimization"
    - "Advanced natural language processing"
    - "Real-time knowledge streaming"

# API ENDPOINT TESTING
api_testing:
  instructions: |
    To test the main API endpoints, use the following curl commands:
      - Knowledge endpoint:
        curl -X GET "http://localhost:8000/api/v1/knowledge"
      - RAG endpoint:
        curl -X GET "http://localhost:8000/api/v1/rag"
      - System endpoint:
        curl -X GET "http://localhost:8000/api/v1/system"
      - Health check:
        curl -X GET "http://localhost:8000/health"
    All endpoints are config-driven and return live data from the configured external API.
    No static, mock, or test data is used. All agent metadata is set via config.

# CONFIGURATION OVERRIDES
config_overrides:
  description: |
    All configuration is centralized and can be overridden via environment variables or a .env file.
    The following environment variables are available for customization:
      - EXTERNAL_API__PLACEHOLDER_BASE_URL: Base URL for external placeholder API (default: https://jsonplaceholder.typicode.com)
      - EXTERNAL_API__KNOWLEDGE_ENDPOINT: Path for knowledge endpoint (default: /posts/1)
      - EXTERNAL_API__RAG_ENDPOINT: Path for RAG endpoint (default: /users/1)
      - EXTERNAL_API__SYSTEM_ENDPOINT: Path for system endpoint (default: /todos/1)
      - EXTERNAL_API__AGENT_NAME: Agent name for metadata (default: AnonymousAgent)
      - EXTERNAL_API__AGENT_VERSION: Agent version for metadata (default: 1.0.0)
      - API_SERVER__HOST: API server host (default: 0.0.0.0)
      - API_SERVER__PORT: API server port (default: 8000)
      - API_SERVER__ENVIRONMENT: Environment (development/production)
      - LOGGING__LEVEL: Logging level (default: info)
      - SECURITY__ALLOWED_HOSTS: Comma-separated list of allowed hosts
      - SECURITY__CORS_ORIGINS: Comma-separated list of allowed CORS origins
    To override, set the environment variable before starting the app, or add it to a .env file in the project root. 